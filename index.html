<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Fadhil Ginting</title>

    <meta name="author" content="Fadhil Ginting">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.svg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Muhammad Fadhil Ginting
                </p>


                <p>I am a PhD candidate in AI Robotics at Stanford University</a> advised by <a href="https://mykel.kochenderfer.com/">Prof. Mykel Kochenderfer</a> in the <a href="https://sisl.stanford.edu/">Stanford Intelligent System Laboratory</a> (SISL), part of the <a href="https://ai.stanford.edu/">Stanford Artificial Intelligence Laboratory</a> (SAIL). My research is supported by the Stanford Graduate Fellowship and in collaboration with <a href="https://www.jpl.nasa.gov/">NASA Jet Propulsion Laboratory (JPL)</a> and a robotics startup <a href="https://fieldai.com/">Field AI</a>.</p>

                <p>Before joining Stanford, I was a visiting researcher at NASA JPL for two years and was one of the key members in the 
                  <a href="https://costar.jpl.nasa.gov">JPL-led team</a> for the DARPA Subterranean Challenge
                  <a href="https://spectrum.ieee.org/nasa-jpl-team-costar-darpa-subt-urban-circuit-systems-track">that won the 2020 DARPA Subterranean Challenge Urban Circuit</a> .</p>

                <p>I completed my Master’s degree in Robotics at ETH Zurich. I received a Bachelor of Science in Electrical Engineering from Institut Teknologi Bandung, graduating as the valedictorian.</p>



                <p style="text-align:center">
                  <a href="mailto:ginting@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Fadhil_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://bit.ly/ginting-scholar">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/mfadhilginting">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/mfadhilgtg/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Fadhil.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Fadhil.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Updates</h2>
            <ul id="news">
              <li><i>[July 2025]</i>&nbsp; Our paper <a href="https://mind-palace-laeqa.github.io/">Enter the Mind Palace</a> got accepted to CoRL 2025!</li>
              <li><i>[July 2025]</i>&nbsp; Our workshop proposal at CoRL 2025 got accepted — <a href="https://sites.google.com/view/corl-2025-safe-rol-workshop">2nd Workshop on Safe and Robust Robot Learning for Operation in the Real World</a>.</li>
              <li><i>[June 2025]</i>&nbsp; I attended RSS 2025 in Los Angeles.</li>
              <li><i>[May 2025]</i>&nbsp; Attending ICRA 2025 in Atlanta, presenting two papers and organizing a workshop.</li>
              <li><i>[May 2025]</i>&nbsp; We organized the workshop <a href="https://sites.google.com/view/reliable-embodied-ai"><b>Towards Reliable and Trustworthy Embodied AI in Everyday Scenarios</b></a> at ICRA 2025.</li>
              <li><i>[January 2025]</i>&nbsp; Two <a href="https://saycomply.github.io/">papers</a> accepted at ICRA 2025.</li>
              <li><i>[November 2024]</i>&nbsp; Our Addendum to Nebula paper is published at IEEE Transcation on Field Robotics.</li>
              <li><i>[October 2024]</i>&nbsp; I was at TED AI event in San Francisco and giving Field AI robot demo. Our talk will be released soon!</li>
              <li><i>[October 2024]</i>&nbsp; I was at IROS in Abu Dhabi, UAE, presenting our <a href="https://arxiv.org/pdf/2401.17191">SB2G paper</a>.</li>
              <li><i>[October 2024]</i>&nbsp; I presented a poster at Bay Area Robotics Symposium (BARS) on <a href="https://saycomply.github.io/">SayComply</a>.</li>
              <li><i>[July 2024]</i>&nbsp; I was at RSS in Delft, Netherlands, presenting our <a href="https://arxiv.org/pdf/2405.09822">SEEK paper</a>.</li>
              <li><i>[June 2024]</i>&nbsp; Our paper on semantic-aware object search got accepted to IROS 2024.</li>
              <li><i>[June 2024]</i>&nbsp; Our work is featured in IEEE Spectrum's Video Friday.</li>
              <li><i>[May 2024]</i>&nbsp; Our paper on semantic reasoning for object goal navigation got accepted to RSS 2024!</li>
              <li><i>[January 2024]</i>&nbsp; I gave a research talk at Stanford AA 229 course.</li>
              <li><i>[October 2023]</i>&nbsp; I presented a poster at Bay Area Robotics Symposium (BARS).</li>
              <li><i>[June 2023]</i>&nbsp; I started a research internship at Field AI.</li>
              <li><i>[May 2023]</i>&nbsp; I was at ICRA in London, UK, presenting our <a href="https://arxiv.org/pdf/2401.17191">SBG paper</a>.</li>
              <li><i>[May 2023]</i>&nbsp; I passed the Stanford PhD qualifying exam!</li>
              <li><i>[January 2023]</i>&nbsp; Our work on locomotion adaptation with semantic belief graph is accepted to ICRA 2023.</li>
              <li><i>[October 2024]</i>&nbsp; I was at IROS in Kyoto, Japan, presenting our multi-robot task allocation paper.</li>
              <li><i>[June 2022]</i>&nbsp; Our work on capability-aware task allocation got accepted to IROS 2022.</li>
              <li><i>[October 2021]</i>&nbsp; I gave a talk on lessons learned in the SubT Challenge at Stanford MSL.</li>
              <li><i>[September 2021]</i>&nbsp; Excited to start my PhD at Stanford!</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Research</h2>
          <p>
            My research interests lie in enabling embodied AI for robots to navigate and interact with unstructured environments using risk-aware autonomy and large foundation models.
          </p>
          <p>
            I am a full-stack roboticist with experience in developing cutting-edge algorithms for perception, planning, control, and communication, as well as deploying robots in the field for real-world use cases.
          </p>

          
        </td>
      </tr>
    </tbody></table>
  

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr onmouseout="seek_stop()" onmouseover="seek_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/saycomply.png' width=100%>
        </div>
        <script type="text/javascript">
          function seek_start() {
            document.getElementById('saycomply_image').style.opacity = "1";
          }

          function seek_stop() {
            document.getElementById('saycomply_image').style.opacity = "0";
          }
          seek_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2411.11323">
          <span class="papertitle">SayComply: Grounding Field Robotic Tasks in Operational Compliance through Retrieval-Based Language Models</span>
        </a>
        <br>
        <strong>Muhammad Fadhil Ginting</strong>, Dong-Ki Kim, Sung-Kyun Kim, Bandi Jai Khrisna,
        <br> 
        Mykel Kochenderfer, Shayegan Omidshafiei, Ali-akbar Agha-mohammadi
        <br>
        <em>Under review</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2411.11323">Arxiv</a>, <a href="https://saycomply.github.io/">Website</a>

        <p></p>
        <p>
          We propose a task planning method for robots that must comply with operational manuals in real-world settings using a tree-based retrieval augmented generation technique.
        </p>
      </td>
    </tr>
    <tr onmouseout="seek_stop()" onmouseover="seek_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/seek.png' width=100%>
        </div>
        <script type="text/javascript">
          function seek_start() {
            document.getElementById('seek_image').style.opacity = "1";
          }

          function seek_stop() {
            document.getElementById('seek_image').style.opacity = "0";
          }
          seek_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2405.09822">
          <span class="papertitle">SEEK: Semantic Reasoning for Object Goal Navigation in Real World Inspection Tasks</span>
        </a>
        <br>
        <strong>Muhammad Fadhil Ginting</strong>, Sung-Kyun Kim, David Fan, Matteo Palieri, 
        <br>
        Mykel Kochenderfer, Ali-akbar Agha-mohammadi
        <br>
        <em>Robotics: Science and Systems</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2405.09822">Arxiv</a>
        <p></p>
        <p>
        We propose a probabilistic planning method for object-goal navigation that uses relational semantic knowledge and prior spatial configuration for real-world inspection.
        </p>
      </td>
    </tr>
    <tr onmouseout="sb2g_stop()" onmouseover="sb2g_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/sb2g.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2401.17191">
          <span class="papertitle">Semantic Belief Behavior Graph: Enabling Autonomous Robot Inspection in Unknown Environments</span>
        </a>
        <br>
        <strong>Muhammad Fadhil Ginting</strong>, David D. Fan, Sung-Kyun Kim, 
        <br>
        Mykel J. Kochenderfer, and Ali-akbar Agha-mohammadi
        <br>
        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2401.17191">Arxiv</a>
        <p></p>
        <p>
          We propose a belief-space task planning framework for semantic-based navigation in real world inspection.
        </p>
      </td>
    </tr>
    
    <tr onmouseout="sbg_stop()" onmouseover="sbg_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/sbg.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2304.00645">
          <span class="papertitle">Safe and Efficient Navigation in Extreme Environments using Semantic Belief Graphs</span>
        </a>
        <br>
        <strong>M. F. Ginting</strong>, S. K. Kim, O. Peltzer, J. Ott, S. Jung, M. J. Kochenderfer, and A. Agha-mohammadi
        <br>
        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023
        <br>
        <a href="https://arxiv.org/pdf/2304.00645">Arxiv</a>
      </td>
    </tr>
    
    <tr onmouseout="conops_stop()" onmouseover="conops_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/conops.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9981631">
          <span class="papertitle">Capability-Aware Task Allocation and Team Formation Analysis for Cooperative Exploration of Complex Environments</span>
        </a>
        <br>
        <strong>M. F. Ginting</strong>, K. Otsu, M. J. Kochenderfer, and A. Agha-mohammadi
        <br>
        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/9981631">Paper</a>
      </td>
    </tr>
    
    <tr onmouseout="lamp2_stop()" onmouseover="lamp2_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/lamp2.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2205.13135">
          <span class="papertitle">LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging Large-Scale Underground Environments</span>
        </a>
        <br>
        Y. Chang, K. Ebadi, C. E. Denniston, <strong>M. F. Ginting</strong>, A. Rosinol, A. Reinke, M. Palieri, J. Shi, A. Chatterjee,
        <br>
        B. Morrell, A. Agha-mohammadi, L. Carlone
        <br>
        <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2022
        <br>
        <a href="https://arxiv.org/pdf/2205.13135">Arxiv</a>
      </td>
    </tr>
    
    <tr onmouseout="braille_stop()" onmouseover="braille_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/spot_cave.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="#">
          <span class="papertitle">Autonomous Mapping and Characterization of Terrestrial Lava Caves Using Quadruped Robots: Preparing for a Mission to a Planetary Cave</span>
        </a>
        <br>
        J. G. Blank, B. Morrell, A. Bouman, T. Touma, <strong>M. F. Ginting</strong>, C. Patterson, A. Agha-mohammadi
        <br>
        <em>Workshop on Terrestrial Analogs for Planetary Exploration</em>, 2021
      </td>
    </tr>
    
    <tr onmouseout="nebula_stop()" onmouseover="nebula_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/nebula_robot.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2103.11470">
          <span class="papertitle">Nebula: Quest for Robotic Autonomy in Challenging Environments; Team CoSTAR at the DARPA Subterranean Challenge</span>
        </a>
        <br>
        <em>Journal of Field Robotics</em>, 2021
        <br>
        <a href="https://arxiv.org/pdf/2103.11470">Arxiv</a>
      </td>
    </tr>
    
    <tr onmouseout="chord_stop()" onmouseover="chord_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/chord.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9364680">
          <span class="papertitle">CHORD: Distributed Data-sharing via Hybrid ROS 1 and 2 for Multi-robot Exploration of Large-scale Complex Environments</span>
        </a>
        <br>
        <strong>M. F. Ginting</strong>, K. Otsu, J. A. Edlund, J. Gao, and A. Agha-Mohammadi
        <br>
        <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2021
        <br>
        <a href="https://ieeexplore.ieee.org/document/9364680">Paper</a>
      </td>
    </tr>
    
    <tr onmouseout="copilot_stop()" onmouseover="copilot_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/copilot.jpg' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9438530">
          <span class="papertitle">Copilot MIKE: An Autonomous Assistant for Multi-Robot Operations in Cave Exploration</span>
        </a>
        <br>
        M. Kaufmann, T. S. Vaquero, G. J. Correa, K. Otsu, <strong>M. F. Ginting</strong>, G. Beltrame, A. Agha-Mohammadi
        <br>
        <em>IEEE Aerospace Conference</em>, 2021
        <br>
        <a href="https://ieeexplore.ieee.org/document/9438530">Paper</a>
      </td>
    </tr>
    
    <tr onmouseout="spot_stop()" onmouseover="spot_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/auspot.png' width=100%>
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2010.09259">
          <span class="papertitle">Autonomous Spot: Long-range Autonomous Exploration of Extreme Environments with Legged Locomotion</span>
        </a>
        <br>
        <strong>M. F. Ginting*</strong>, A. Bouman*, N. Alatur*, M. Palieri, D. D. Fan, T. Touma, T. Pailevanian, S. K. Kim,
        <br>
        K. Otsu, J. Burdick, and A. Agha-Mohammadi
        <br>
        <em>IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2020
        <br>
        <strong>Best Paper Award on Safety, Security, and Rescue Robotics</strong>
        <br>
        <a href="https://arxiv.org/pdf/2010.09259">Paper</a>
      </td>
    </tr>       
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Media Coverage</h2>
      </td>
    </tr>
  </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

  <tr onmouseout="nebula_stop()" onmouseover="nebula_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/news_intern.png' width=100%>
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://www.jpl.nasa.gov/edu/news/2022/5/19/interns-lead-the-way-in-darpa-robotics-challenge-and-find-their-futures">
        <span class="papertitle">Interns Lead the Way in DARPA Robotics Challenge and Find Their Futures</span>
      </a>
    </td>
  </tr>
  
  <tr onmouseout="chord_stop()" onmouseover="chord_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/costar_ieeespectrum.jpg' width=100%>
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://spectrum.ieee.org/nasa-jpl-team-costar-darpa-subt-urban-circuit-systems-track">
        <span class="papertitle">How JPL's Team CoSTAR Won the DARPA SubT Challenge: Urban Circuit Systems Track</span>
      </a>
    </td>
  </tr>
  
  <tr onmouseout="copilot_stop()" onmouseover="copilot_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/news_auspot.webp' width=100%>
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://www.space.com/ai-mars-robot-dogs-agu">
        <span class="papertitle">Meet Au-Spot, the AI robot dog that's training to explore caves on Mars</span>
      </a>
    </td>
  </tr>
  
  
  <tr onmouseout="spot_stop()" onmouseover="spot_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/costar_jplnews.jpg' width=100%>
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://www.jpl.nasa.gov/news/robots-autonomously-navigate-underground-in-darpa-challenge">
        <span class="papertitle">Robots Autonomously Navigate Underground in DARPA Challenge </span>
      </a>
    </td>
  </tr>       
  </tbody></table>

          
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Website design credits to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
          </p>
        </td>
      </tr>
    </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
